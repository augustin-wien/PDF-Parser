{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/funny/Documents/Projects/230701-Parsing-Tool/augustin-plugin/sample_data/AUG_590_Straw_umgebaut/\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import base64\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import fitz\n",
    "import requests\n",
    "import re\n",
    "from fitz import Document, Page, Rect\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "global_save_path = os.environ.get(\"SAVE_PATH\") + \"AUG_590_Straw_umgebaut/\"\n",
    "print(global_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = fitz.open(\"../sample_data/AUG_590_Straw_umgebaut/AUG_590_Straw_umgebaut.pdf\")\n",
    "page = src.load_page(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurence = page.search_for(\"Gratis\")\n",
    "\n",
    "if len(occurence) != 1:\n",
    "    print(\"Error: Found more than one or no occurence of 'Gratis' on the first page\")\n",
    "else:\n",
    "    x0, y0, x1, y1 = occurence[0]\n",
    "\n",
    "pix1 = page.get_pixmap(clip=(0,0,page.rect.width,y0))\n",
    "# Save the image to the new directory\n",
    "name_png = f\"{global_save_path}page-{page.number}1.png\"\n",
    "pix1.save(name_png)\n",
    "\n",
    "pix2 = page.get_pixmap(clip=(0, y0, 180, page.rect.height))\n",
    "# Save the image to the new directory\n",
    "name_png = f\"{global_save_path}page-{page.number}2.png\"\n",
    "pix2.save(name_png)\n",
    "\n",
    "pix3 = page.get_pixmap(clip=(180, y0, 320, page.rect.height))\n",
    "# Save the image to the new directory\n",
    "name_png = f\"{global_save_path}page-{page.number}3.png\"\n",
    "pix3.save(name_png)\n",
    "\n",
    "pix4 = page.get_pixmap(clip=(320, y0, 460, page.rect.height))\n",
    "# Save the image to the new directory\n",
    "name_png = f\"{global_save_path}page-{page.number}4.png\"\n",
    "pix4.save(name_png)\n",
    "\n",
    "pix5 = page.get_pixmap(clip=(460, y0, page.rect.width, page.rect.height))\n",
    "# Save the image to the new directory\n",
    "name_png = f\"{global_save_path}page-{page.number}5.png\"\n",
    "pix5.save(name_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract following pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab 7 euro (280.91339111328125, 234.12710571289062, 419.2013854980469, 286.07110595703125) 43.0\n",
      "Page number: 2\n",
      "Augenschmaus (33.7322998046875, 469.8849792480469, 244.6123046875, 518.2049560546875) 40.0\n",
      "Page number: 3\n",
      "Ohrwurm (33.7322998046875, 46.95587921142578, 166.8083038330078, 95.27587890625) 40.0\n",
      "Page number: 3\n",
      "There are six headlines on the page\n"
     ]
    }
   ],
   "source": [
    "# Read page text as a dictionary, suppressing extra spaces in CJK fonts\n",
    "\n",
    "for index, page in enumerate(src):\n",
    "    headlines = []\n",
    "    if index == 0:\n",
    "        continue\n",
    "    blocks = page.get_text(\"dict\", flags=11)[\"blocks\"]\n",
    "    for b in blocks:\n",
    "        for l in b[\"lines\"]:\n",
    "            for s in l[\"spans\"]:\n",
    "                if s[\"size\"] > 30:\n",
    "                    print(s[\"text\"], s[\"bbox\"], s[\"size\"])\n",
    "                    print(f\"Page number: {index}\")\n",
    "                    headlines += s[\"text\"], s[\"bbox\"], s[\"size\"]\n",
    "    if len(headlines) == 0:\n",
    "        # Set three text parts for the three columns over the whole page\n",
    "        pix1 = page.get_pixmap(clip=(0,0,180,page.rect.height))\n",
    "        # Save the image to the new directory\n",
    "        name_png = f\"{global_save_path}page-{page.number}1.png\"\n",
    "        pix1.save(name_png)\n",
    "\n",
    "        pix2 = page.get_pixmap(clip=(180,0,320,page.rect.height))\n",
    "        # Save the image to the new directory\n",
    "        name_png = f\"{global_save_path}page-{page.number}2.png\"\n",
    "        pix2.save(name_png)\n",
    "\n",
    "        pix3 = page.get_pixmap(clip=(320,0,460,page.rect.height))\n",
    "        # Save the image to the new directory\n",
    "        name_png = f\"{global_save_path}page-{page.number}3.png\"\n",
    "        pix3.save(name_png)\n",
    "    elif len(headlines) == 3:\n",
    "        # Set six text parts in total\n",
    "        # First three columns above the header for section above the header\n",
    "        x0, y0, x1, y1 = headlines[1]\n",
    "        pix1 = page.get_pixmap(clip=(0,0,160,y0))\n",
    "        # Save the image to the new directory\n",
    "        name_png = f\"{global_save_path}page-{page.number}1.png\"\n",
    "        pix1.save(name_png)\n",
    "\n",
    "        pix2 = page.get_pixmap(clip=(160,0,300,y0))\n",
    "        # Save the image to the new directory\n",
    "        name_png = f\"{global_save_path}page-{page.number}2.png\"\n",
    "        pix2.save(name_png)\n",
    "\n",
    "        pix3 = page.get_pixmap(clip=(300,0,440,y0))\n",
    "        # Save the image to the new directory\n",
    "        name_png = f\"{global_save_path}page-{page.number}3.png\"\n",
    "        pix3.save(name_png)\n",
    "\n",
    "        # Last three columns below the header for section below the header\n",
    "        pix4 = page.get_pixmap(clip=(0,y0,160,page.rect.height))\n",
    "        # Save the image to the new directory\n",
    "        name_png = f\"{global_save_path}page-{page.number}4.png\"\n",
    "        pix4.save(name_png)\n",
    "\n",
    "        pix5 = page.get_pixmap(clip=(160,y0,300,page.rect.height))\n",
    "        # Save the image to the new directory\n",
    "        name_png = f\"{global_save_path}page-{page.number}5.png\"\n",
    "        pix5.save(name_png)\n",
    "\n",
    "        pix6 = page.get_pixmap(clip=(300,y0,440,page.rect.height))\n",
    "        # Save the image to the new directory\n",
    "        name_png = f\"{global_save_path}page-{page.number}6.png\"\n",
    "        pix6.save(name_png)\n",
    "\n",
    "    elif len(headlines) == 6:\n",
    "        print(\"There are six headlines on the page\")\n",
    "        # TODO implement the case where there are six headlines on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Get image from first page, upload it and use it as featured_media image for post\n",
    "2. Add category \"strawanzerin\" to post\n",
    "## First page\n",
    "1. Search for word \"Gratis\" and get its coordinates\n",
    "2. Below the y-axis of the given coordinates extract text (either in get.text() or in four divided parts to have it in the correct)\n",
    "3. Set the word \"Gratis\" as ## header\n",
    "4. Let the dates either have the same colour as they are given or let them have a smaller header like ###\n",
    "5. No clue what to do with \"Tipp aus der Redaktion\" -> for now add this whole text to the end of the post\n",
    "\n",
    "## Next pages\n",
    "1. Check for headlines by font size > 30. If found, look for next headers \"ab 7 Euro, Ohrwurm, Augenschmaus\"\n",
    "2. Same as in first page: Get coordinates from found header\n",
    "3. \"Virtually split\" page by parsing through three text fields above the header (as part of the header section before) and three text fields below\n",
    "   - Same option if two headers in one page \n",
    "4. Extract text -> Remove headline quotes such \"bis 7 Euro\", \"Gratis\" right after text extraction\n",
    "\n",
    "## Most right text part\n",
    "- Extract fourth (most right) text part: Add text of fourth part of the first page with text of fourth part following pages in one variable, after parsing for common headers\n",
    "- Add first header to Gratis section\n",
    "- Add headers with ab 7 euro to \"Ab 7 Euro\" section\n",
    "- Add last information to the end of the whole post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
